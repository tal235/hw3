Box({'name': 'debug', 'seed': 42, 'num_epochs': 50, 'learning_rate': 0.0001, 'accumulation_steps': 1, 'do_train': True, 'do_eval_on_train': False, 'do_eval': True, 'do_test': False, 'data_args': {'max_seq_length': 64, 'batch_size': 1, 'shuffle': True, 'eval_batch_size': 1}, 'model_args': {'output_size': 5, 'dropout': 0.5, 'lstm_args': {'input_size': 50, 'hidden_size': 256, 'num_layers': 3, 'bias': True, 'batch_first': True, 'dropout': 0.2, 'bidirectional': True, 'proj_size': 0}}})
Loading datasets
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\new-env\lib\site-packages\pandas\core\apply.py", line 873, in apply_series_generator
    results[i] = self.f(v)
  File "C:\Users\TALSHA\OneDrive - rafael.co.il\Course\03 - AI Specialist\NLP\HW\hw3\dataloading.py", line 40, in <lambda>
    self.df[INPUT_IDS] = self.df.apply(lambda row: self.tokenize(row), axis=1)
  File "C:\Users\TALSHA\OneDrive - rafael.co.il\Course\03 - AI Specialist\NLP\HW\hw3\dataloading.py", line 58, in tokenize
    for i, token in enumerate(gensim.utils.tokenize(text, lowercase=True)):
  File "D:\ProgramData\Anaconda3\envs\new-env\lib\site-packages\gensim\utils.py", line 262, in tokenize
    text = to_unicode(text, encoding, errors=errors)
  File "D:\ProgramData\Anaconda3\envs\new-env\lib\site-packages\gensim\utils.py", line 365, in any2unicode
    return str(text, encoding, errors=errors)
TypeError: decoding to str: need a bytes-like object, Series found